{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6tc18kSVcVu"
   },
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hMZCiliNNyk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkhwvXumNsA_"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                            PREAMBLE                                             #\n",
    "###################################################################################################\n",
    "\n",
    "log = lambda *args: print(datetime.now().strftime('%H:%M:%S'), ':', *args)\n",
    "\n",
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, mean_pixel, std_pixel\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i + B], self.y[i:i + B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, mean_pixel, std_pixel = load_cifar10()\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)\n",
    "\n",
    "get_X_train_sample = lambda: next(iter(train_dset))[0][7] * std_pixel + mean_pixel\n",
    "\n",
    "def select_device(use_gpu=True):\n",
    "    from tensorflow.python.client import device_lib\n",
    "    log(device_lib.list_local_devices())\n",
    "    device = '/device:GPU:0' if use_gpu else '/CPU:0'\n",
    "    log('Using device: ', device)\n",
    "    return device\n",
    "\n",
    "device = select_device(use_gpu=USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZBT4w_GN9re"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                              PART 1                                             #\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - TensorFlow Tensor of shape (N, D1, ..., DM)\n",
    "\n",
    "    Output:\n",
    "    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n",
    "    \"\"\"\n",
    "        ############################################################################\n",
    "    # TODO: (1.a) Reshape tensor x into shape (N, D1 * ... * DM)               #\n",
    "    ############################################################################\n",
    "    x_flat = tf.reshape(x, [tf.shape(x)[0], -1])\n",
    "    #shape = x.get_shape().as_list()\n",
    "    #dim = np.prod(shape[1:]) \n",
    "    #x_flat = tf.reshape(x, [-1, dim])\n",
    "    ############################################################################\n",
    "    #                              END OF YOUR CODE                            #\n",
    "    ############################################################################\n",
    "    return x_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7s3DWlz_fbN"
   },
   "outputs": [],
   "source": [
    "def kaiming_normal(shape):\n",
    "    \"\"\"\n",
    "    He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n",
    "    ImageNet Classification, ICCV 2015, https://arxiv.org/abs/1502.01852\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:\n",
    "        fan_in, fan_out = shape[0], shape[1]\n",
    "    elif len(shape) == 4:\n",
    "        fan_in, fan_out = np.prod(shape[:3]), shape[3]\n",
    "    return tf.random_normal(shape) * np.sqrt(2.0 / fan_in)\n",
    "\n",
    "\n",
    "def convnet_init():\n",
    "    \"\"\"\n",
    "    Initialize the weights of a Three-Layer ConvNet, for use with the\n",
    "    three_layer_convnet function defined above.\n",
    "    \"\"\"\n",
    "\n",
    "    conv_w1 = tf.Variable(kaiming_normal([5, 5, 3, 32]))\n",
    "    conv_b1 = tf.Variable(tf.zeros(32,))\n",
    "\n",
    "    conv_w2 = tf.Variable(kaiming_normal([5, 5, 32, 32]))\n",
    "    conv_b2 = tf.Variable(tf.zeros(32,))\n",
    "\n",
    "    conv_w3 = tf.Variable(kaiming_normal([5, 5, 32, 64]))\n",
    "    conv_b3 = tf.Variable(tf.zeros(64,))\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO: (1.a), (2.a) Initialize the remaining parameters.                  #\n",
    "    ############################################################################\n",
    "    #conv_w4 = None\n",
    "    #conv_b4 = None\n",
    "    #conv_w5 = tf.Variable(kaiming_normal([4, 4, 64, 10]))\n",
    "    #conv_b5 = tf.Variable(tf.zeros(10,))\n",
    "    #conv_w5 = tf.Variable(kaiming_normal([8, 8, 32, 10]))\n",
    "    #conv_b5 = tf.Variable(tf.zeros(10,))\n",
    "    conv_w5 = tf.Variable(kaiming_normal([16, 16, 32, 10]))\n",
    "    conv_b5 = tf.Variable(tf.zeros(10,))\n",
    "    \n",
    "\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "\n",
    "    #params = [conv_w1, conv_b1, conv_w2, conv_b2, conv_w3, conv_b3, conv_w5, conv_b5]\n",
    "    #params = [conv_w1, conv_b1, conv_w2, conv_b2, conv_w5, conv_b5]\n",
    "    params = [conv_w1, conv_b1,conv_w5, conv_b5]   \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq24kQPnAYss"
   },
   "outputs": [],
   "source": [
    "def convnet_forward(x, params):\n",
    "    \"\"\"\n",
    "    A three-layer convolutional network.\n",
    "\n",
    "    Args:\n",
    "    - x: A TensorFlow Tensor of shape (N, H, W, 3) giving a minibatch of images\n",
    "    - params: A list of TensorFlow Tensors giving the weights and biases for the network.\n",
    "    \"\"\"\n",
    "    #[conv_w1, conv_b1, conv_w2, conv_b2, conv_w3, conv_b3, conv_w5, conv_b5] = params\n",
    "    #[conv_w1, conv_b1, conv_w2, conv_b2, conv_w5, conv_b5] =params\n",
    "    [conv_w1, conv_b1, conv_w5, conv_b5] =params\n",
    "    # block 1\n",
    "    x1_1_pad = tf.pad(x, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    x1_2_conv = tf.nn.conv2d(x1_1_pad, conv_w1, [1, 1, 1, 1], padding='VALID') + conv_b1\n",
    "    x1_3_pad = tf.pad(x1_2_conv, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    x1_4_pool = tf.nn.max_pool(x1_3_pad, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    x1_5_relu = tf.nn.relu(x1_4_pool)\n",
    "\n",
    "    # block 2\n",
    "    #x2_1_pad = tf.pad(x1_5_relu, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    #x2_2_conv = tf.nn.conv2d(x2_1_pad, conv_w2, [1, 1, 1, 1], padding='VALID') + conv_b2\n",
    "    #x2_3_relu = tf.nn.relu(x2_2_conv)\n",
    "    #x2_4_pad = tf.pad(x2_3_relu, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    #x2_5_pool = tf.nn.avg_pool(x2_4_pad, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # block 3\n",
    "    #x3_1_pad = tf.pad(x2_5_pool, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    #x3_2_conv = tf.nn.conv2d(x3_1_pad, conv_w3, [1, 1, 1, 1], padding='VALID') + conv_b3\n",
    "    #x3_3_relu = tf.nn.relu(x3_2_conv)\n",
    "    #x3_4_pad = tf.pad(x3_3_relu, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    #x3_5_pool = tf.nn.avg_pool(x3_4_pad, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO: (1.a), (2.a) Implement the remaining forward pass.                 #\n",
    "    ############################################################################\n",
    "     \n",
    "    #x5_1_conv =  tf.nn.conv2d(x3_5_pool, conv_w5, [1, 1, 1, 1], padding='VALID') + conv_b5\n",
    "    #x5_1_conv =  tf.nn.conv2d(x2_5_pool, conv_w5, [1, 1, 1, 1], padding='VALID') + conv_b5\n",
    "    x5_1_conv =  tf.nn.conv2d(x1_5_relu, conv_w5, [1, 1, 1, 1], padding='VALID') + conv_b5\n",
    "    ############################################################################\n",
    "    #                              END OF YOUR CODE                            #\n",
    "    ############################################################################\n",
    "\n",
    "    logits = flatten(x5_1_conv)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbQkfRi3GjRU"
   },
   "outputs": [],
   "source": [
    "def three_layer_convnet_test():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.device(device):\n",
    "        x = tf.placeholder(tf.float32)\n",
    "\n",
    "        # block 1\n",
    "        conv_w1 = tf.zeros([5, 5, 3, 32])\n",
    "        conv_b1 = tf.zeros(32)\n",
    "\n",
    "        # block 2\n",
    "        conv_w2 = tf.zeros([5, 5, 32, 32])\n",
    "        conv_b2 = tf.zeros(32)\n",
    "\n",
    "        # block 3\n",
    "        conv_w3 = tf.zeros([5, 5, 32, 64])\n",
    "        conv_b3 = tf.zeros(64)\n",
    "\n",
    "        ############################################################################\n",
    "        # TODO: (1.a), (2.a) Initialize the parameters.                            #\n",
    "        ############################################################################\n",
    "\n",
    "        #conv_w4=None\n",
    "        #conv_b4=None\n",
    "        #conv_w5 = tf.zeros([4, 4, 64, 10])\n",
    "        #conv_w5 = tf.zeros([8, 8, 32, 10])\n",
    "        conv_w5 = tf.zeros([16, 16, 32, 10])\n",
    "        conv_b5 = tf.zeros(10)\n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "        \n",
    "        #params = [conv_w1, conv_b1, conv_w2, conv_b2, conv_w3, conv_b3,  conv_w5, conv_b5]\n",
    "        #params = [conv_w1, conv_b1, conv_w2, conv_b2,  conv_w5, conv_b5]\n",
    "        params = [conv_w1, conv_b1, conv_w5, conv_b5]\n",
    "        logits = convnet_forward(x, params)\n",
    "\n",
    "    # Inputs to convolutional layers are 4-dimensional arrays with shape [batch_size, height, width, channels]\n",
    "    x_np = np.zeros((64, 32, 32, 3))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        logits_np = sess.run(logits, feed_dict={x: x_np})\n",
    "        log('logits_np has shape', format(logits_np.shape))\n",
    "with tf.device('/cpu:0'):\n",
    "    three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeVcnQjsW7nC"
   },
   "outputs": [],
   "source": [
    "def training_step(logits, y, params, learning_rate):\n",
    "    \"\"\"\n",
    "    Set up the part of the computational graph which makes a training step.\n",
    "\n",
    "    Args:\n",
    "    - logits: TensorFlow Tensor of shape (N, C) giving classification scores for\n",
    "      the model.\n",
    "    - y: TensorFlow Tensor of shape (N,) giving ground-truth labels for scores;\n",
    "      y[i] == c means that c is the correct class for scores[i].\n",
    "    - params: List of TensorFlow Tensors giving the weights of the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for gradient\n",
    "      descent step.\n",
    "\n",
    "    Returns:\n",
    "    - loss: A TensorFlow Tensor of shape () (scalar) giving the loss for this\n",
    "      batch of data; evaluating the loss also performs a gradient descent step\n",
    "      on params (see above).\n",
    "    \"\"\"\n",
    "    # First compute the loss; the first line gives losses for each example in\n",
    "    # the mini-batch, and the second averages the losses across the batch\n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(losses)\n",
    "\n",
    "    # Compute the gradient of the loss with respect to each parameter of the the\n",
    "    # network. This is a very magical function call: TensorFlow internally\n",
    "    # traverses the computational graph starting at loss backward to each element\n",
    "    # of params, and uses back-propagation to figure out how to compute gradients;\n",
    "    # it then adds new operations to the computational graph which compute the\n",
    "    # requested gradients, and returns a list of TensorFlow Tensors that will\n",
    "    # contain the requested gradients when evaluated.\n",
    "    grad_params = tf.gradients(loss, params)\n",
    "\n",
    "    # Make a gradient descent step on all of the model parameters.\n",
    "    new_weights = []\n",
    "    for w, grad_w in zip(params, grad_params):\n",
    "        new_w = tf.assign_sub(w, learning_rate * grad_w)\n",
    "        new_weights.append(new_w)\n",
    "\n",
    "    # Insert a control dependency so that evaluating the loss causes a weight\n",
    "    # update to happen.\n",
    "    with tf.control_dependencies(new_weights):\n",
    "        return tf.identity(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q79X2gKAXEpv"
   },
   "outputs": [],
   "source": [
    "def train(model_fn, init_fn, learning_rate, epochs, print_every=100):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10.\n",
    "\n",
    "    Args:\n",
    "    - model_fn: A Python function that performs the forward pass of the model\n",
    "      using TensorFlow; it should have the following signature:\n",
    "      scores = model_fn(x, params) where x is a TensorFlow Tensor giving a\n",
    "      minibatch of image data, params is a list of TensorFlow Tensors holding\n",
    "      the model weights, and scores is a TensorFlow Tensor of shape (N, C)\n",
    "      giving scores for all elements of x.\n",
    "    - init_fn: A Python function that initializes the parameters of the model.\n",
    "      It should have the signature params = init_fn() where params is a list\n",
    "      of TensorFlow Tensors holding the (randomly initialized) weights of the\n",
    "      model.\n",
    "    - learning_rate: Python float giving the learning rate to use for SGD.\n",
    "    \"\"\"\n",
    "    # First clear the default graph\n",
    "    tf.reset_default_graph()\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    # Set up the computational graph for performing forward and backward passes,\n",
    "    # and weight updates.\n",
    "    with tf.device(device):\n",
    "        # Set up placeholders for the data and labels\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        params = init_fn()  # Initialize the model parameters\n",
    "        scores = model_fn(x, params)  # Forward pass of the model\n",
    "        loss = training_step(scores, y, params, learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Now we actually run the graph many times using the training data\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables that will live in the graph\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            log('epoch {:>4d}/{:>4d}'.format(epoch, epochs))\n",
    "            epoch_time = time()\n",
    "            for t, (x_np, y_np) in enumerate(train_dset):\n",
    "                # Run the graph on a batch of training data; recall that asking\n",
    "                # TensorFlow to evaluate loss will cause an SGD step to happen.\n",
    "                feed_dict = {x: x_np, y: y_np}\n",
    "                loss_np = sess.run(loss, feed_dict=feed_dict)\n",
    "\n",
    "                # Periodically print the loss and check accuracy on the val set\n",
    "                if t % print_every == 0:\n",
    "                    num_correct, num_samples, acc = get_accuracy(sess, val_dset, x, scores, is_training)\n",
    "                    log('   iteration = {:>4d}, loss = {:>8.4f}, accuracy = {:>8.2f}%'.format(t, loss_np, acc))\n",
    "\n",
    "            train_losses.append(loss_np)\n",
    "            test_accuracies.append(acc)\n",
    "\n",
    "            log('epoch {:>4d} took {:>.2f}s'.format(epoch, time()-epoch_time))\n",
    "\n",
    "        return params, sess.run(params), train_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Llz4ZKDXXHEL"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(sess, dset, x, logits, is_training=None):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model.\n",
    "\n",
    "    Args:\n",
    "    - sess: A TensorFlow Session that will be used to run the graph\n",
    "    - dset: A Dataset object on which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - scores: A TensorFlow Tensor representing the scores output from the\n",
    "      model; this is the Tensor we will ask TensorFlow to evaluate.\n",
    "\n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(logits, feed_dict=feed_dict)\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return num_correct, num_samples, 100 * acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wz9X1g4VXLNN"
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: (1.b) Adjust learning-rate and number of epochs.                   #\n",
    "############################################################################\n",
    "learning_rate = 6e-3\n",
    "epochs = 60\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################\n",
    "\n",
    "params, params_val, train_losses, test_accuracies = train(convnet_forward, convnet_init, learning_rate, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umdoGA2vXX7I"
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: (1.c) Plot.                                                        #\n",
    "############################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1, 60, 60)\n",
    "y1= train_losses\n",
    "y2= test_accuracies\n",
    "plt.figure()\n",
    "plt.plot(x,y1)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss)\")\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig('1_loss.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,y2)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Test-accuracy)\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig('2_accuracy.png')\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                             END OF YOUR CODE                             #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKGVYB1hXcRV"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                              PART 2                                             #\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "def plot_kernels_on_grid(kernel, grid_Y, grid_X, pad = 1):\n",
    "    \"\"\"\n",
    "    Visualize convolutional features as an image.\n",
    "\n",
    "    Args:\n",
    "      kernel:            tensor of shape [Y, X, NumChannels, NumKernels]\n",
    "      (grid_Y, grid_X):  shape of the grid. Require: NumKernels == grid_Y * grid_X\n",
    "                           User is responsible of how to break into two multiples.\n",
    "      pad:               number of black pixels around each filter (between them)\n",
    "\n",
    "    Return:\n",
    "      Tensor of shape [(Y+2*pad)*grid_Y, (X+2*pad)*grid_X, NumChannels, 1].\n",
    "    \"\"\"\n",
    "\n",
    "    x_min = tf.reduce_min(kernel)\n",
    "    x_max = tf.reduce_max(kernel)\n",
    "\n",
    "    kernel1 = (kernel - x_min) / (x_max - x_min)\n",
    "\n",
    "    # pad X and Y\n",
    "    x1 = tf.pad(kernel1, tf.constant([[pad,pad], [pad, pad], [0,0], [0,0]]), mode='CONSTANT')\n",
    "\n",
    "    # X and Y dimensions, w.r.t. padding\n",
    "    Y = kernel1.get_shape()[0] + 2 * pad\n",
    "    X = kernel1.get_shape()[1] + 2 * pad\n",
    "\n",
    "    channels = kernel1.get_shape()[2]\n",
    "\n",
    "    # put NumKernels to the 1st dimension\n",
    "    x2 = tf.transpose(x1, (3, 0, 1, 2))\n",
    "    # organize grid on Y axis\n",
    "    x3 = tf.reshape(x2, tf.stack([grid_X, Y * grid_Y, X, channels]))\n",
    "\n",
    "    # switch X and Y axes\n",
    "    x4 = tf.transpose(x3, (0, 2, 1, 3))\n",
    "    # organize grid on X axis\n",
    "    x5 = tf.reshape(x4, tf.stack([1, X * grid_X, Y * grid_Y, channels]))\n",
    "\n",
    "    # back to normal order (not combining with the next step for clarity)\n",
    "    x6 = tf.transpose(x5, (2, 1, 3, 0))\n",
    "\n",
    "    # to tf.image_summary order [batch_size, height, width, channels], where in this case batch_size == 1\n",
    "    x7 = tf.transpose(x6, (3, 0, 1, 2))\n",
    "\n",
    "    # scale to [0, 255] and convert to uint8\n",
    "    return tf.image.convert_image_dtype(x7, dtype=tf.uint8)\n",
    "\n",
    "\n",
    "grid = plot_kernels_on_grid(params_val[0], 4, 8)\n",
    "#saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ############################################################################\n",
    "    # TODO: Retrieve image of kernels from symbolic 'grid' variable.           #\n",
    "    ############################################################################\n",
    "    \n",
    "    grid_val = sess.run(grid)\n",
    "    \n",
    "    \n",
    "    #tf.reshape(grid,[-1,32])\n",
    " \n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "    img = Image.fromarray(grid_val[0], 'RGB')\n",
    "    img.save('3_kernels.png')\n",
    "from google.colab import files\n",
    "files.download( \"3_kernels.png\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pgr-rAkNXoaB"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                              PART 3                                             #\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "def plot_filter_grid(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20, 12))\n",
    "    n_columns = 8\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(units[0, :, :, i], interpolation='nearest')\n",
    "\n",
    "\n",
    "def conv1_activations(x, conv_w1, conv_b1):\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO: Compute activations for the first conv layer.                      #\n",
    "    ############################################################################\n",
    "    x1 = tf.pad(x, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='CONSTANT', constant_values=0)\n",
    "    output=tf.nn.conv2d(x1, conv_w1, [1, 1, 1, 1], padding='VALID') + conv_b1\n",
    "  \n",
    "  \n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "    return output\n",
    "\n",
    "\n",
    "image = get_X_train_sample()\n",
    "plt.imshow(np.squeeze(image).astype(np.uint8), interpolation='nearest')\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.savefig('4_data.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    hidden_1 = sess.run(conv1_activations(x, params[0], params[1]), feed_dict={x: image, params[0]: params_val[0], params[1]: params_val[1]})\n",
    "    plot_filter_grid(hidden_1)\n",
    "    plt.savefig('5_activations.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "log('done.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project0.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
