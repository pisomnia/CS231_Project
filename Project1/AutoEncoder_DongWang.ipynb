{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KBxDWJTeyHB"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgbKKzB0lx1O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.utils.data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWeAcyYWQ0fj"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBySKcTdjN8Q"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_j7uHhtWlx1X"
   },
   "outputs": [],
   "source": [
    "#now access your file uploaded in your google drive folder \"/temp\"\n",
    "image_appearance = np.load(\"img_warped.npy\")\n",
    "image_appearance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgF91np9lx1S"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xGOpqKmlx1U"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder_Appearance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder_Appearance, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            # TODO: Fill in the encoder structure\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),          \n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(                    \n",
    "            # TODO: Fill in the FC layer structure\n",
    "            Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 50),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # TODO: Fill in the decoder structure\n",
    "            # Hint: De-Conv in PyTorch: ConvTranspose2d \n",
    "            Reshape(-1,50, 1, 1),\n",
    "            nn.ConvTranspose2d(50, 128, kernel_size=8, stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "            self.code50 = self.encoder(x)\n",
    "            self.fcd = self.fc1(self.code50)  \n",
    "            return self.decoder(self.fcd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mT1_sawelx1a"
   },
   "outputs": [],
   "source": [
    "image_appearance = image_appearance / 255\n",
    "training_data = image_appearance[:800]\n",
    "testing_data = image_appearance[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QODVEmkblx1c"
   },
   "outputs": [],
   "source": [
    "training_data = training_data.astype(np.float32)\n",
    "testing_data = testing_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBhPLOojlx1f"
   },
   "outputs": [],
   "source": [
    "#show an example\n",
    "random_idx = np.random.randint(len(training_data))\n",
    "print(random_idx)\n",
    "plt.imshow(training_data[random_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VFN3MKrmlx1k"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(training_data.transpose((0,3,1,2)), batch_size=100, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBR8Ka5ilx1m"
   },
   "outputs": [],
   "source": [
    "print(\"GPU?: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPRwqyj8lx1q"
   },
   "outputs": [],
   "source": [
    "learning_rate = 7e-4\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xJhul1Blx1s"
   },
   "outputs": [],
   "source": [
    "model_appearance = AutoEncoder_Appearance()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "      model_appearance = model_appearance.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_appearance.parameters(), lr=learning_rate)\n",
    "                             #weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcjL47splx1u",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, x in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model_appearance(x)\n",
    "        loss = criterion(output, x)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "        if batch_idx % 10 == 0 and (epoch+1)%50==0:\n",
    "            print('epoch [{}/{}]'\n",
    "                  .format(epoch+1, num_epochs),\"batch: \", batch_idx, \" loss: \",loss.data)\n",
    "            pic = output.cpu().data.numpy()[0]\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(pic.transpose(1,2,0))\n",
    "            \n",
    "            \n",
    "            pic = x.cpu().data.numpy()[0]\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(pic.transpose(1,2,0))\n",
    "    \n",
    "            plt.show()\n",
    "\n",
    "torch.save(model_appearance.state_dict(), \"autoencoder_appearance.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzu1fJOgJ3eU"
   },
   "outputs": [],
   "source": [
    "num_epoch=np.array([50, 100, 150, 200, 250, 300, 350, 400, 450,  500])\n",
    "rc_err_appearance=np.array([0.0032,0.0029,0.0024,0.0025,0.0022,0.0021,0.0021,0.0020,0.0017,0.0017])\n",
    "plt.figure()\n",
    "plt.plot(num_epoch,rc_err_appearance)\n",
    "plt.xlabel(\"Number of epoches\")\n",
    "plt.ylabel(\"Reconstruction  Error)\")\n",
    "plt.savefig('ae_1_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vofnp1ApLKG1"
   },
   "outputs": [],
   "source": [
    "image_landmarks = np.load(\"image_landmarks.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mustfoqplx1y"
   },
   "outputs": [],
   "source": [
    "###Define AutoEncoder for landmarks\n",
    "class AutoEncoder_Landmarks(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder_Landmarks, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(68*2, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 68*2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.code10 = self.encoder(x)\n",
    "        return self.decoder(self.code10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HyYCIdDelx14"
   },
   "outputs": [],
   "source": [
    "training_landmarks = image_landmarks[:800]\n",
    "testing_landmarks = image_landmarks[800:]\n",
    "\n",
    "training_landmarks_flatten = training_landmarks.reshape(-1, 136)\n",
    "testing_landmarks_flatten = testing_landmarks.reshape(-1, 136)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUxtQokmlx19"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_landmark_mean = StandardScaler(with_std = False)\n",
    "\n",
    "scaler_landmark_mean.fit(training_landmarks_flatten)\n",
    "\n",
    "mean_landmark = scaler_landmark_mean.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qfJ2_zVlx2A"
   },
   "outputs": [],
   "source": [
    "mean_landmark = mean_landmark.reshape(68, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4h4z1IZlx2C"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_landmark = MinMaxScaler()\n",
    "training_landmarks_flatten_scaled = scaler_landmark.fit_transform(training_landmarks_flatten)\n",
    "testing_landmarks_flatten_scaled = scaler_landmark.transform(testing_landmarks_flatten)\n",
    "\n",
    "\n",
    "training_landmarks_flatten_scaled = training_landmarks_flatten_scaled.astype(np.float32)\n",
    "testing_landmarks_flatten_scaled = testing_landmarks_flatten_scaled.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VsxMQ_xlx2J"
   },
   "outputs": [],
   "source": [
    "landmark_train_loader = \\\n",
    "    torch.utils.data.DataLoader(training_landmarks_flatten_scaled, batch_size=100, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZY6GEqmvlx2L"
   },
   "outputs": [],
   "source": [
    "learning_rate = 7e-4\n",
    "num_epochs = 500\n",
    "weight_decay = 1e-6\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1X9EmNklx2O"
   },
   "outputs": [],
   "source": [
    "model_landmark = AutoEncoder_Landmarks()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "      model_landmark = model_landmark.cuda()\n",
    "\n",
    "criterion_landmark = nn.MSELoss()\n",
    "optimizer_landmark = torch.optim.Adam(model_landmark.parameters(), lr=learning_rate,\n",
    "                             weight_decay= weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5m-gVKxlx2P"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, x in enumerate(landmark_train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        \n",
    "        # ===================forward=====================\n",
    "        output = model_landmark(x)\n",
    "        loss = criterion_landmark(output, x)\n",
    "        # ===================backward====================\n",
    "        optimizer_landmark.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_landmark.step()\n",
    "        # ===================log========================\n",
    "        if batch_idx % 10 == 0 and (epoch+1)%50==0:\n",
    "            print('epoch [{}/{}]'\n",
    "                  .format(epoch+1, num_epochs),\"batch: \", batch_idx, \" loss: \",loss.data)\n",
    "      \n",
    "      # if epoch % 500 == 0:\n",
    "     #torch.save(model.state_dict(), \"/content/drive/My Drive/temp/autoencoder_landmark.pt\")\n",
    "torch.save(model_landmark.state_dict(), \"autoencoder_landmark.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26mttFP5Lcwt"
   },
   "outputs": [],
   "source": [
    "#num_epoch=np.array([50, 100, 150, 200, 250, 300, 350, 400, 450,  500])\n",
    "#rc_err_lanmarks=np.array([0.0004,0.00049,0.0005,0.0003,0.0004,0.0021,0.0021,0.0020,0.0017,0.0017])\n",
    "#plt.figure()\n",
    "#plt.plot(num_epoch,rc_err_appearance)\n",
    "#plt.xlabel(\"Number of epoches\")\n",
    "#plt.ylabel(\"Reconstruction  Error)\")\n",
    "#plt.savefig('ae_1_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vNvP4BUlx2R"
   },
   "outputs": [],
   "source": [
    "model_landmark.load_state_dict(torch.load('autoencoder_landmark.pt'))\n",
    "model_landmark = model_landmark.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-UB6mIjlx2U"
   },
   "outputs": [],
   "source": [
    "# #generate random landmarks\n",
    "# random_landmark_code10 = torch.from_numpy(np.random.rand(50, 10))\n",
    "# random_landmark_code10 = random_landmark_code10.float()\n",
    "# generated_landmarks = model_landmark.decoder(random_landmark_code10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZPK6ek1lx2W"
   },
   "outputs": [],
   "source": [
    "model_appearance.load_state_dict(torch.load(\"autoencoder_appearance.pt\"))\n",
    "model_appearance = model_appearance.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUS992OUlx2a"
   },
   "outputs": [],
   "source": [
    "#generate images\n",
    "random_image_code50 = torch.from_numpy(np.random.rand(50, 50))\n",
    "random_image_code50 = random_image_code50.float()\n",
    "\n",
    "\n",
    "generated_images = model_appearance.decoder(random_image_code50)\n",
    "\n",
    "generated_images = generated_images.data.numpy().transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgF6NSeflx2e"
   },
   "outputs": [],
   "source": [
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF_dTVZalx2j"
   },
   "outputs": [],
   "source": [
    "#show 50 synthesized images\n",
    "for i in range(50):\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgBP87UMlx2p"
   },
   "outputs": [],
   "source": [
    "sample_testing_images = model_appearance(torch.from_numpy(testing_data[:20].transpose((0,3,1,2))))\n",
    "\n",
    "sample_testing_images = sample_testing_images.data.numpy().transpose((0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VFISBNTElx2r"
   },
   "outputs": [],
   "source": [
    "sample_testing_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88PanI3_lx2u"
   },
   "outputs": [],
   "source": [
    "sample_testing_landmarks = model_landmark(torch.from_numpy(testing_landmarks_flatten_scaled[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uhevvn2vlx2v"
   },
   "outputs": [],
   "source": [
    "sample_testing_landmarks = sample_testing_landmarks.data.numpy()\n",
    "sample_testing_landmarks = scaler_landmark.inverse_transform(sample_testing_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PS2fTyGElx2y"
   },
   "outputs": [],
   "source": [
    "sample_testing_landmarks = sample_testing_landmarks.reshape(-1, 68, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFsYv_-xM2UC"
   },
   "outputs": [],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ic-rluqClx20"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import sys\n",
    "import datetime\n",
    "import imageio\n",
    "\n",
    "##################################\n",
    "# Apply affine transform calculated using srcTri and dstTri to src and\n",
    "# output an image of size.\n",
    "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
    "    \n",
    "    # Given a pair of triangles, find the affine transform.\n",
    "    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
    "    \n",
    "    # Apply the Affine Transform just found to the src image\n",
    "    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point) :\n",
    "    if point[0] < rect[0] :\n",
    "        return False\n",
    "    elif point[1] < rect[1] :\n",
    "        return False\n",
    "    elif point[0] > rect[0] + rect[2] :\n",
    "        return False\n",
    "    elif point[1] > rect[1] + rect[3] :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "#calculate delanauy triangle\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "    #create subdiv\n",
    "    subdiv = cv2.Subdiv2D(rect);\n",
    "    \n",
    "    # Insert points into subdiv\n",
    "    for p in points:\n",
    "        p1=(int(p[0]),int(p[1]))\n",
    "        if p1[1]<=rect[2]-1 and p1[0]<=rect[2]-1 and p1[1]>=rect[0] and p1[0]>=rect[0]:\n",
    "            subdiv.insert(p1) \n",
    "    \n",
    "    triangleList = subdiv.getTriangleList();\n",
    "    \n",
    "    delaunayTri = []\n",
    "    \n",
    "    pt = []    \n",
    "        \n",
    "    for t in triangleList:        \n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])        \n",
    "        \n",
    "        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "            ind = []\n",
    "            #Get face-points (from 68 face detector) by coordinates\n",
    "            for j in range(0, 3):\n",
    "                for k in range(0, len(points)):                    \n",
    "                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "                        ind.append(k)    \n",
    "            # Three points form a triangle. Triangle array corresponds to the file tri.txt in FaceMorph \n",
    "            if len(ind) == 3:                                                \n",
    "                delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "        \n",
    "        pt = []        \n",
    "            \n",
    "    \n",
    "    return delaunayTri\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def warpTriangle(img1, img2, t1, t2) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = [] \n",
    "    t2Rect = []\n",
    "    t2RectInt = []\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "        t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "    w,h,num_chans = img1.shape\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r2[3], r2[2], num_chans), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    #img2Rect = np.zeros((r2[3], r2[2]), dtype = img1Rect.dtype)\n",
    "    \n",
    "    size = (r2[2], r2[3])\n",
    "\n",
    "    img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
    "    if num_chans==1:\n",
    "        img2Rect=np.reshape(img2Rect,(r2[3], r2[2], num_chans))\n",
    "    \n",
    "    img2Rect = img2Rect * mask\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    if num_chans==1:\n",
    "        img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( 1.0 - mask )\n",
    "     \n",
    "    else:\n",
    "        img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )\n",
    "     \n",
    "    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect \n",
    "\n",
    "###################################\n",
    "def warp(Image,sc,tc):\n",
    "    '''\n",
    "    Image: the image to be warped\n",
    "    sc: original landmarks\n",
    "    tc: warped landmarks\n",
    "    '''\n",
    "    HW,_,_=Image.shape\n",
    "    cornerps=[[0,0],[0,HW-1],[HW-1,0],[HW-1,HW-1]]\n",
    "    #cornerps=[[0,0],[0,HW-1],[HW-1,0],[HW-1,HW-1],[0,np.floor(HW/2)],[np.floor(HW/2),0],[HW-1,np.floor(HW/2)],[np.floor(HW/2),HW-1]]\n",
    "\n",
    "    scl=sc.astype(np.int64).tolist()+cornerps\n",
    "    tcl=tc.astype(np.int64).tolist()+cornerps\n",
    "    imgWarped = np.copy(Image);    \n",
    "    rect = (0, 0, HW, HW)\n",
    "    dt = calculateDelaunayTriangles(rect,tcl)\n",
    "# Apply affine transformation to Delaunay triangles\n",
    "    for i in range(0, len(dt)):\n",
    "        t1 = []\n",
    "        t2 = []\n",
    "        \n",
    "        #get points for img1, img2 corresponding to the triangles\n",
    "        for j in range(0, 3):\n",
    "            t1.append(scl[dt[i][j]])\n",
    "            t2.append(tcl[dt[i][j]])\n",
    "        \n",
    "        warpTriangle(Image, imgWarped, t1, t2)\n",
    "    return imgWarped\n",
    "\n",
    "#########################################\n",
    "def plot(samples,Nh,Nc,channel,IMG_HEIGHT, IMG_WIDTH):\n",
    "    fig = plt.figure(figsize=(Nc, Nh))\n",
    "    plt.clf()\n",
    "    gs = gridspec.GridSpec(Nh, Nc)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples[0:Nh*Nc,:,:,:]):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        if channel==1:\n",
    "            image=sample.reshape(IMG_HEIGHT, IMG_WIDTH)\n",
    "            immin=(image[:,:]).min()\n",
    "            immax=(image[:,:]).max()\n",
    "            image=(image-immin)/(immax-immin+1e-8)\n",
    "            plt.imshow(image,cmap ='gray')\n",
    "        else:\n",
    "            image=sample.reshape(IMG_HEIGHT, IMG_WIDTH,channel)\n",
    "            immin=(image[:,:,:]).min()\n",
    "            immax=(image[:,:,:]).max()\n",
    "            image=(image-immin)/(immax-immin+1e-8)\n",
    "            plt.imshow(image)\n",
    "    return fig \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ej9qOF6Glx22"
   },
   "outputs": [],
   "source": [
    "def get_warped_images(images, landmarks, to_landmarks):\n",
    "    warped_images = np.zeros(images.shape)\n",
    "    H = warped_images.shape[0]\n",
    "    for i in range(H):\n",
    "        if i % int(H / 5) == 0:\n",
    "            print(\"Running at...\", i,\"/\", H)\n",
    "        warped_images[i] = warp(images[i], landmarks[i], to_landmarks[i])\n",
    "        \n",
    "    print(\"Finished\")\n",
    "    return warped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgCLspWmlx25"
   },
   "outputs": [],
   "source": [
    "warped_back_images = get_warped_images(sample_testing_images, [mean_landmark for _ in range(20)], sample_testing_landmarks)\n",
    "warped_real_images = get_warped_images(testing_data[:20], [mean_landmark for _ in range(20)], testing_landmarks[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78e6nadslx2-"
   },
   "outputs": [],
   "source": [
    "#plot top 10 reconstructed faces\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    pic = warped_back_images[i]\n",
    "    plt.imshow(pic)\n",
    "    plt.scatter(sample_testing_landmarks[i,:,0], sample_testing_landmarks[i,:,1],s =0.5)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    pic = warped_real_images[i]\n",
    "    plt.imshow(pic)\n",
    "    plt.scatter(testing_landmarks[i,:,0], testing_landmarks[i,:,1],s =0.5)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RZF2oGRlx3I"
   },
   "outputs": [],
   "source": [
    "def calculate_variance_rank(model, images):\n",
    "    scaler_variance = StandardScaler()\n",
    "    images_encode50 = model.encoder(torch.from_numpy(images)).data.numpy()\n",
    "    scaler_variance.fit(images_encode50)\n",
    "    \n",
    "    def rank_simple(vector):\n",
    "        return sorted(range(len(vector)), key=vector.__getitem__)\n",
    "\n",
    "    return rank_simple(scaler_variance.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5373aO83lx3L"
   },
   "outputs": [],
   "source": [
    "ranks = calculate_variance_rank(model_appearance, training_data.transpose((0,3,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gT6phwRElx3N"
   },
   "outputs": [],
   "source": [
    "print(\"the first 4 dimensions of the latent variables of appearance that have the maximal variance: \", ranks[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BD0OUPFBlx3P"
   },
   "outputs": [],
   "source": [
    "#get a random train image and show the interpolation along those four encoders\n",
    "random_idx = np.random.randint(800)\n",
    "sample_image = training_data[random_idx]\n",
    "sample_landmark = training_landmarks[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_AqINLJxlx3R"
   },
   "outputs": [],
   "source": [
    "original_image = warp(sample_image, mean_landmark, sample_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEWsbm3plx3U"
   },
   "outputs": [],
   "source": [
    "#original image\n",
    "plt.imshow(original_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vObYPYblx3W"
   },
   "outputs": [],
   "source": [
    "#generate encoded parts\n",
    "sample_torch = torch.from_numpy(sample_image).unsqueeze(0).permute(0,3,1,2)\n",
    "sample_code = model_appearance.encoder(sample_torch).data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFypbfW1lx3c"
   },
   "outputs": [],
   "source": [
    "interpolation_encodes = np.array([sample_code]*10)\n",
    "\n",
    "#interpolate along four ranks with largest variance\n",
    "ranks_first_four = ranks[::-1][:4]\n",
    "\n",
    "for rank in ranks_first_four:\n",
    "    for i in range(10):\n",
    "        interpolation_encodes[i][rank] = 0.3*i\n",
    "\n",
    "    interpolation_decodes = model.decoder(torch.from_numpy(interpolation_encodes))\n",
    "\n",
    "    plt.figure(figsize = (12,12)) \n",
    "\n",
    "    for i in range(10):\n",
    "        plt.subplot(1,10,i+1)\n",
    "        pic = interpolation_decodes[i].data.numpy().transpose(1,2,0)\n",
    "        warp_back_pic = warp(pic, mean_landmark, sample_landmark)\n",
    "        plt.scatter(sample_landmark[:,0], sample_landmark[:,1], s=0.5)\n",
    "        plt.imshow(warp_back_pic)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wt3yDCSZlx3h"
   },
   "outputs": [],
   "source": [
    "interpolation_encodes = np.array([sample_code]*25)\n",
    "\n",
    "#interpolate along two ranks with largest variance\n",
    "rank_first, rank_second = ranks[-1], ranks[-2]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        interpolation_encodes[5 * i + j][rank_first] = 0.5*i\n",
    "        interpolation_encodes[5 * i + j][rank_second] = 0.5*j\n",
    "        \n",
    "\n",
    "interpolation_decodes = model.decoder(torch.from_numpy(interpolation_encodes))\n",
    "\n",
    "plt.figure(figsize = (6,6)) \n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    pic = interpolation_decodes[i].data.numpy().transpose(1,2,0)\n",
    "    warp_back_pic = warp(pic, mean_landmark, sample_landmark)\n",
    "    plt.scatter(sample_landmark[:,0], sample_landmark[:,1], s=0.5)\n",
    "    plt.imshow(warp_back_pic)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AutoEncoder_DongWang.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
